{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diabetes_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DIABETES PREDICTION BUT USING PYSPARK INSTEAD OF PANDAS"
      ],
      "metadata": {
        "id": "77UUdLPYokzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be doing Predictions on the Diabetes dataset, but not tradionally like how we used to do using pandas, but instead we will be doing it using a new method called as Pyspark.\n",
        "PySpark is similar to pandas, it has a dataframe, but the key difference between both of them is that, a pandas dataframe is mutable, where as a Pyspark dataframe is immutable. It is very essential, when the integrity of the dataset is crucial to the business application and this is where the pyspark library is useful."
      ],
      "metadata": {
        "id": "ayJ4VB_0nckQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are completely new to the Pyspark concept, but know little bit about pandas library, I suggest you visit this site:\n",
        " https://sparkbyexamples.com/pyspark/pandas-vs-pyspark-dataframe-with-examples/"
      ],
      "metadata": {
        "id": "CxPCIRCro0b9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HgHZ6hauadH",
        "outputId": "3af83691-2022-41c3-ecc8-64a76502c509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 38 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 56.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=b8a4cb2b822d2cbc6d68f1b65687091e97227ea64e23d7f6209a56216878b417\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ],
      "source": [
        "#Installing all the important libraries\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"spark\").getOrCreate()\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.feature import VectorAssembler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/education454/diabetes_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WN2-Ecdum_J",
        "outputId": "af10e43c-b662-4501-d529-cb412ec044aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diabetes_dataset'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls diabetes_dataset "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D6nxQ7lu0I4",
        "outputId": "fe96259c-8537-49a2-e1bf-58728d21d6ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diabetes.csv  new_test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdf = spark.read.csv('/content/diabetes_dataset/diabetes.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "c42H3QsrvoXj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaC8UuQJ3Tbm",
        "outputId": "97244ae5-1ae1-4708-ccd2-2ed9c862f5f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          2|    138|           62|           35|      0|33.6|                   0.127| 47|      1|\n",
            "|          0|     84|           82|           31|    125|38.2|                   0.233| 23|      0|\n",
            "|          0|    145|            0|            0|      0|44.2|                    0.63| 31|      1|\n",
            "|          0|    135|           68|           42|    250|42.3|                   0.365| 24|      1|\n",
            "|          1|    139|           62|           41|    480|40.7|                   0.536| 21|      0|\n",
            "|          0|    173|           78|           32|    265|46.5|                   1.159| 58|      0|\n",
            "|          4|     99|           72|           17|      0|25.6|                   0.294| 28|      0|\n",
            "|          8|    194|           80|            0|      0|26.1|                   0.551| 67|      0|\n",
            "|          2|     83|           65|           28|     66|36.8|                   0.629| 24|      0|\n",
            "|          2|     89|           90|           30|      0|33.5|                   0.292| 42|      0|\n",
            "|          4|     99|           68|           38|      0|32.8|                   0.145| 33|      0|\n",
            "|          4|    125|           70|           18|    122|28.9|                   1.144| 45|      1|\n",
            "|          3|     80|            0|            0|      0| 0.0|                   0.174| 22|      0|\n",
            "|          6|    166|           74|            0|      0|26.6|                   0.304| 66|      0|\n",
            "|          5|    110|           68|            0|      0|26.0|                   0.292| 30|      0|\n",
            "|          2|     81|           72|           15|     76|30.1|                   0.547| 25|      0|\n",
            "|          7|    195|           70|           33|    145|25.1|                   0.163| 55|      1|\n",
            "|          6|    154|           74|           32|    193|29.3|                   0.839| 39|      0|\n",
            "|          2|    117|           90|           19|     71|25.2|                   0.313| 21|      0|\n",
            "|          3|     84|           72|           32|      0|37.2|                   0.267| 28|      0|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDNf2l0q3l8_",
        "outputId": "1a89a1cc-fea0-44fc-cb17-c577e3ac2d3c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Pregnancies: integer (nullable = true)\n",
            " |-- Glucose: integer (nullable = true)\n",
            " |-- BloodPressure: integer (nullable = true)\n",
            " |-- SkinThickness: integer (nullable = true)\n",
            " |-- Insulin: integer (nullable = true)\n",
            " |-- BMI: double (nullable = true)\n",
            " |-- DiabetesPedigreeFunction: double (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Outcome: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can see the schema of the dataset. Understanding the schema is really important before you start analyzing the data. You may make useful assumptions required for the dataset, just by looking at the data's schema."
      ],
      "metadata": {
        "id": "pVqSiImWpHUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sdf.count(),len(sdf.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6steHpD-3uee",
        "outputId": "20f09686-deb8-4d6f-b9f6-6cc36268af7f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting the number of 0's and 1's in the output column of the dataset.\n",
        "sdf.groupby('Outcome').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geMSYmn638Xx",
        "outputId": "b3c29e26-c180-4a54-8b3a-d6e46fbc2139"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|Outcome|count|\n",
            "+-------+-----+\n",
            "|      1|  684|\n",
            "|      0| 1316|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjil-Wu84Lq1",
        "outputId": "fef6ab36-e406-4bb1-84ef-4a72bdd4fb95"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+------------------+------------------+-----------------+-----------------+------------------+------------------------+------------------+------------------+\n",
            "|summary|      Pregnancies|           Glucose|     BloodPressure|    SkinThickness|          Insulin|               BMI|DiabetesPedigreeFunction|               Age|           Outcome|\n",
            "+-------+-----------------+------------------+------------------+-----------------+-----------------+------------------+------------------------+------------------+------------------+\n",
            "|  count|             2000|              2000|              2000|             2000|             2000|              2000|                    2000|              2000|              2000|\n",
            "|   mean|           3.7035|          121.1825|           69.1455|           20.935|           80.254|32.192999999999984|     0.47092999999999974|           33.0905|             0.342|\n",
            "| stddev|3.306063032730656|32.068635649902916|19.188314815604098|16.10324290992682|111.1805335457595| 8.149900701279762|      0.3235525586811429|11.786423106049496|0.4744982342297426|\n",
            "|    min|                0|                 0|                 0|                0|                0|               0.0|                   0.078|                21|                 0|\n",
            "|    max|               17|               199|               122|              110|              744|              80.6|                    2.42|                81|                 1|\n",
            "+-------+-----------------+------------------+------------------+-----------------+-----------------+------------------+------------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, in the above output, some of the feature columns like Glucose and BloodPressure have values 0, which does not makes sense, since it never can be 0, unless he/she is dead. Jokes apart, these values need to be replaced by some alternate values, which is why, we will be fetching those values, and then replacing them by the value of the mean of the column which we have already found in the above code."
      ],
      "metadata": {
        "id": "j9DXkydmHpzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing the 0 values from features to the mean values.\n",
        "#Also check for missing or null values\n",
        "for cl in sdf.columns:\n",
        "  print(cl+\":\",sdf[sdf[cl].isNull()].count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl8s9N6R4P0g",
        "outputId": "0ee7dbba-8ecb-4392-c735-f7902a9cff0c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregnancies: 0\n",
            "Glucose: 0\n",
            "BloodPressure: 0\n",
            "SkinThickness: 0\n",
            "Insulin: 0\n",
            "BMI: 0\n",
            "DiabetesPedigreeFunction: 0\n",
            "Age: 0\n",
            "Outcome: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see, that there are no null values in the dataset, which makes half of our job easy. Atleast that's what I think."
      ],
      "metadata": {
        "id": "LxyTQWkfIJ03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the total number of 0's in the columns of Glucose, Blood Pressure, SkinThickness, Insulin and BMI.\n",
        "def check_zeros():\n",
        "  feature_names = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']\n",
        "  #For printing the name of each column and the subsequent value.\n",
        "  for i in feature_names:\n",
        "    print(i+\"\",sdf[sdf[i]==0].count())\n",
        "check_zeros()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PROisiii6Ynj",
        "outputId": "4563fb6b-4173-4f28-e5f1-4bb3af923ec7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Glucose 13\n",
            "BloodPressure 90\n",
            "SkinThickness 573\n",
            "Insulin 956\n",
            "BMI 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's iterate through each column, and find out which column has what as their mean value. Then we will find out the positions of values in the respective columns with 0, and replace it with the mean value of that column."
      ],
      "metadata": {
        "id": "DY1BFh6NImgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sdf.columns[1:6]:\n",
        "  value = sdf.agg({i:'mean'}).first()[0]\n",
        "  print(\"Mean value for {} is {}\".format(i,int(value)))\n",
        "  sdf = sdf.withColumn(i,when(sdf[i]==0,int(value)).otherwise(sdf[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYFkREQJ6q0N",
        "outputId": "013b2f0a-b23d-4b0d-d54b-5161500fcaf4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean value for Glucose is 121\n",
            "Mean value for BloodPressure is 69\n",
            "Mean value for SkinThickness is 20\n",
            "Mean value for Insulin is 80\n",
            "Mean value for BMI is 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMd7VH5W8iHX",
        "outputId": "c44f1831-cd8b-446c-c7ed-7b89c03835f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          2|    138|           62|           35|     80|33.6|                   0.127| 47|      1|\n",
            "|          0|     84|           82|           31|    125|38.2|                   0.233| 23|      0|\n",
            "|          0|    145|           69|           20|     80|44.2|                    0.63| 31|      1|\n",
            "|          0|    135|           68|           42|    250|42.3|                   0.365| 24|      1|\n",
            "|          1|    139|           62|           41|    480|40.7|                   0.536| 21|      0|\n",
            "|          0|    173|           78|           32|    265|46.5|                   1.159| 58|      0|\n",
            "|          4|     99|           72|           17|     80|25.6|                   0.294| 28|      0|\n",
            "|          8|    194|           80|           20|     80|26.1|                   0.551| 67|      0|\n",
            "|          2|     83|           65|           28|     66|36.8|                   0.629| 24|      0|\n",
            "|          2|     89|           90|           30|     80|33.5|                   0.292| 42|      0|\n",
            "|          4|     99|           68|           38|     80|32.8|                   0.145| 33|      0|\n",
            "|          4|    125|           70|           18|    122|28.9|                   1.144| 45|      1|\n",
            "|          3|     80|           69|           20|     80|32.0|                   0.174| 22|      0|\n",
            "|          6|    166|           74|           20|     80|26.6|                   0.304| 66|      0|\n",
            "|          5|    110|           68|           20|     80|26.0|                   0.292| 30|      0|\n",
            "|          2|     81|           72|           15|     76|30.1|                   0.547| 25|      0|\n",
            "|          7|    195|           70|           33|    145|25.1|                   0.163| 55|      1|\n",
            "|          6|    154|           74|           32|    193|29.3|                   0.839| 39|      0|\n",
            "|          2|    117|           90|           19|     71|25.2|                   0.313| 21|      0|\n",
            "|          3|     84|           72|           32|     80|37.2|                   0.267| 28|      0|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the values with 0 in them, has changed into the mean values of the respective columns."
      ],
      "metadata": {
        "id": "svB5S8lnJA_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now figure out the correlation of each column, with every other column. Correlation basically means how much is one column related to the other column."
      ],
      "metadata": {
        "id": "hd5V65XmJKZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cl in sdf.columns:\n",
        "  print(\"Correlation to outcome for {} is {} \".format(cl,sdf.stat.corr('Outcome',cl)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whIIZnUQ9Mk4",
        "outputId": "c4f534e5-7901-4241-b524-184e9c6c9e91"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation to outcome for Pregnancies is 0.22443699263363961 \n",
            "Correlation to outcome for Glucose is 0.48796646527321064 \n",
            "Correlation to outcome for BloodPressure is 0.17171333286446713 \n",
            "Correlation to outcome for SkinThickness is 0.1659010662889893 \n",
            "Correlation to outcome for Insulin is 0.1711763270226193 \n",
            "Correlation to outcome for BMI is 0.2827927569760082 \n",
            "Correlation to outcome for DiabetesPedigreeFunction is 0.1554590791569403 \n",
            "Correlation to outcome for Age is 0.23650924717620253 \n",
            "Correlation to outcome for Outcome is 1.0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VectorAssember from Spark ML library is a module that allows to convert numerical features into a single vector that is used by the machine learning models.\n",
        "ectorAssembler will have two parameters:\n",
        "1.   inputCols – list of features to combine into a single vector column.\n",
        "2.   outputCol – the new column that will contain the transformed vector\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "orUrQ_J_Jjvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age'], outputCol='features')\n",
        "output_data = assembler.transform(sdf)"
      ],
      "metadata": {
        "id": "S9UFL1AaC2dj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu0ByQgpDfMZ",
        "outputId": "abac55cb-593b-4a06-900c-077c2f5ae083"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Pregnancies: integer (nullable = true)\n",
            " |-- Glucose: integer (nullable = true)\n",
            " |-- BloodPressure: integer (nullable = true)\n",
            " |-- SkinThickness: integer (nullable = true)\n",
            " |-- Insulin: integer (nullable = true)\n",
            " |-- BMI: double (nullable = true)\n",
            " |-- DiabetesPedigreeFunction: double (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Outcome: integer (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the princtSchema output, we can see at the last section, we have a new vector column, which has the data from the all the columns that we have passed in the inputCols."
      ],
      "metadata": {
        "id": "AU_RE3c2J0VH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpaQeGbMEkZ2",
        "outputId": "666430b2-ad81-409e-b286-611915f0181c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+--------------------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|            features|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+--------------------+\n",
            "|          2|    138|           62|           35|     80|33.6|                   0.127| 47|      1|[2.0,138.0,62.0,3...|\n",
            "|          0|     84|           82|           31|    125|38.2|                   0.233| 23|      0|[0.0,84.0,82.0,31...|\n",
            "|          0|    145|           69|           20|     80|44.2|                    0.63| 31|      1|[0.0,145.0,69.0,2...|\n",
            "|          0|    135|           68|           42|    250|42.3|                   0.365| 24|      1|[0.0,135.0,68.0,4...|\n",
            "|          1|    139|           62|           41|    480|40.7|                   0.536| 21|      0|[1.0,139.0,62.0,4...|\n",
            "|          0|    173|           78|           32|    265|46.5|                   1.159| 58|      0|[0.0,173.0,78.0,3...|\n",
            "|          4|     99|           72|           17|     80|25.6|                   0.294| 28|      0|[4.0,99.0,72.0,17...|\n",
            "|          8|    194|           80|           20|     80|26.1|                   0.551| 67|      0|[8.0,194.0,80.0,2...|\n",
            "|          2|     83|           65|           28|     66|36.8|                   0.629| 24|      0|[2.0,83.0,65.0,28...|\n",
            "|          2|     89|           90|           30|     80|33.5|                   0.292| 42|      0|[2.0,89.0,90.0,30...|\n",
            "|          4|     99|           68|           38|     80|32.8|                   0.145| 33|      0|[4.0,99.0,68.0,38...|\n",
            "|          4|    125|           70|           18|    122|28.9|                   1.144| 45|      1|[4.0,125.0,70.0,1...|\n",
            "|          3|     80|           69|           20|     80|32.0|                   0.174| 22|      0|[3.0,80.0,69.0,20...|\n",
            "|          6|    166|           74|           20|     80|26.6|                   0.304| 66|      0|[6.0,166.0,74.0,2...|\n",
            "|          5|    110|           68|           20|     80|26.0|                   0.292| 30|      0|[5.0,110.0,68.0,2...|\n",
            "|          2|     81|           72|           15|     76|30.1|                   0.547| 25|      0|[2.0,81.0,72.0,15...|\n",
            "|          7|    195|           70|           33|    145|25.1|                   0.163| 55|      1|[7.0,195.0,70.0,3...|\n",
            "|          6|    154|           74|           32|    193|29.3|                   0.839| 39|      0|[6.0,154.0,74.0,3...|\n",
            "|          2|    117|           90|           19|     71|25.2|                   0.313| 21|      0|[2.0,117.0,90.0,1...|\n",
            "|          3|     84|           72|           32|     80|37.2|                   0.267| 28|      0|[3.0,84.0,72.0,32...|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Analysis of the dataset."
      ],
      "metadata": {
        "id": "8mj6C_7lKBYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using Logistic Regression Analysis to predict the output. There are other methods which are available for predicting like Naive Bayes and more, but when it comes to binary classification, Logistic Regression analysis makes more astute prediction."
      ],
      "metadata": {
        "id": "dubt0fG4KPFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We will be using Logistic Regression\n",
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "metadata": {
        "id": "Nc7fusqYEox1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = output_data.select('features','Outcome')"
      ],
      "metadata": {
        "id": "eSCEXd8iE1-o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F2iIaDgE8e9",
        "outputId": "6a15436e-2f51-4477-d51f-81ddcf9055f0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- features: vector (nullable = true)\n",
            " |-- Outcome: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be splitting the data in 2 parts, training and testing data. The training data will have 70% of overall data, whereas testing will have reamining 30%. It's not mandatory to do that, you can take any number you like, just make sure that the training split is more than the testing split. This helps in a way that model learns more about the data and can get us good prediction results."
      ],
      "metadata": {
        "id": "a_zFwue_Khbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = final_data.randomSplit([0.7,0.3])\n",
        "models = LogisticRegression(labelCol='Outcome')\n",
        "model = models.fit(train)"
      ],
      "metadata": {
        "id": "IgsFcYEME_tq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = model.summary"
      ],
      "metadata": {
        "id": "wy20rTyjFKDQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary.predictions.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhsxHwaAFQhh",
        "outputId": "6a134b4d-3b9f-44f9-a3d5-0129a9514d45"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+-------------------+\n",
            "|summary|            Outcome|         prediction|\n",
            "+-------+-------------------+-------------------+\n",
            "|  count|               1374|               1374|\n",
            "|   mean|0.34643377001455605|0.26346433770014555|\n",
            "| stddev| 0.4760066386956732| 0.4406724565359349|\n",
            "|    min|                0.0|                0.0|\n",
            "|    max|                1.0|                1.0|\n",
            "+-------+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluator for binary classification, which expects input columns rawPrediction, label and an optional weight column. The rawPrediction column can be of type double (binary 0/1 prediction, or probability of label 1) or of type vector (length-2 vector of raw predictions, scores, or label probabilities).\n",
        "\n",
        "You can get more details in the link:\n",
        "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.BinaryClassificationEvaluator.html"
      ],
      "metadata": {
        "id": "2bfsEnN4K_R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
      ],
      "metadata": {
        "id": "5unUNlznFUbp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.evaluate(test)"
      ],
      "metadata": {
        "id": "U8ABLiyLGrBi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.predictions.show(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNxYFTLcGuwk",
        "outputId": "0a69dc84-8e89-4f2f-f3e6-a9d9e1d5b7cd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------+--------------------+--------------------+----------+\n",
            "|            features|Outcome|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-------+--------------------+--------------------+----------+\n",
            "|[0.0,73.0,69.0,20...|      0|[4.04756103990063...|[0.98283486865127...|       0.0|\n",
            "|[0.0,74.0,52.0,10...|      0|[3.48665316118600...|[0.97030561623887...|       0.0|\n",
            "|[0.0,84.0,64.0,22...|      0|[2.41536709537680...|[0.91799164036427...|       0.0|\n",
            "|[0.0,86.0,68.0,32...|      0|[2.58731957673575...|[0.93004101702774...|       0.0|\n",
            "|[0.0,86.0,68.0,32...|      0|[2.58731957673575...|[0.93004101702774...|       0.0|\n",
            "|[0.0,91.0,68.0,32...|      0|[2.21797861111311...|[0.90185241848705...|       0.0|\n",
            "|[0.0,91.0,80.0,20...|      0|[2.31842695869104...|[0.91039169688789...|       0.0|\n",
            "|[0.0,93.0,60.0,20...|      0|[2.30710677193522...|[0.90946391095931...|       0.0|\n",
            "|[0.0,93.0,60.0,20...|      0|[2.30710677193522...|[0.90946391095931...|       0.0|\n",
            "|[0.0,93.0,60.0,25...|      0|[2.65955005184119...|[0.93459716873538...|       0.0|\n",
            "|[0.0,93.0,100.0,3...|      0|[1.00469027440480...|[0.73197974256818...|       0.0|\n",
            "|[0.0,94.0,69.0,20...|      0|[2.53982402478501...|[0.92688690206023...|       0.0|\n",
            "|[0.0,94.0,69.0,20...|      0|[2.53982402478501...|[0.92688690206023...|       0.0|\n",
            "|[0.0,95.0,64.0,39...|      0|[1.59944867755021...|[0.83194131611229...|       0.0|\n",
            "|[0.0,95.0,64.0,39...|      0|[1.59944867755021...|[0.83194131611229...|       0.0|\n",
            "|[0.0,95.0,80.0,45...|      0|[2.18735922310183...|[0.89910860778850...|       0.0|\n",
            "|[0.0,95.0,85.0,25...|      1|[2.08411726619267...|[0.88934984981850...|       0.0|\n",
            "|[0.0,98.0,82.0,15...|      0|[2.93678556519971...|[0.94963520826122...|       0.0|\n",
            "|[0.0,98.0,82.0,15...|      0|[2.93678556519971...|[0.94963520826122...|       0.0|\n",
            "|[0.0,100.0,88.0,6...|      0|[0.70654580107617...|[0.66963745936149...|       0.0|\n",
            "|[0.0,101.0,64.0,1...|      0|[3.16129703514803...|[0.95935155594899...|       0.0|\n",
            "|[0.0,101.0,64.0,1...|      0|[3.16129703514803...|[0.95935155594899...|       0.0|\n",
            "|[0.0,101.0,65.0,2...|      0|[2.91466629163710...|[0.94856670028232...|       0.0|\n",
            "|[0.0,101.0,76.0,2...|      0|[2.05294833361458...|[0.88624519260069...|       0.0|\n",
            "|[0.0,101.0,76.0,2...|      0|[2.05294833361458...|[0.88624519260069...|       0.0|\n",
            "|[0.0,102.0,52.0,2...|      0|[2.94809266427260...|[0.95017326497474...|       0.0|\n",
            "|[0.0,102.0,52.0,2...|      0|[2.94809266427260...|[0.95017326497474...|       0.0|\n",
            "|[0.0,102.0,64.0,4...|      0|[1.51812367469949...|[0.82026201596158...|       0.0|\n",
            "|[0.0,102.0,64.0,4...|      0|[1.51812367469949...|[0.82026201596158...|       0.0|\n",
            "|[0.0,102.0,75.0,2...|      0|[2.06970107173214...|[0.88792321687314...|       0.0|\n",
            "+--------------------+-------+--------------------+--------------------+----------+\n",
            "only showing top 30 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',labelCol='Outcome')\n",
        "evaluator.evaluate(model.transform(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wXyCZYUGyzc",
        "outputId": "22267c6d-86c1-4548-99f8-cb6afd9fb271"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8541129922708871"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can save the model using model.save() command with the name of model which ever you like."
      ],
      "metadata": {
        "id": "nDH9PvyPLrS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Binary_model\")"
      ],
      "metadata": {
        "id": "cTcNDVrhHgML"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For loading the saved model, you will need a library in the below code I have mentioned how to use and import it."
      ],
      "metadata": {
        "id": "oL9S1_2QLyCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegressionModel"
      ],
      "metadata": {
        "id": "86tekTe0HlG3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegressionModel.load(\"Binary_model\")"
      ],
      "metadata": {
        "id": "AlYAvUO-HtJH"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}